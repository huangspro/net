# 基于计算图的 BP 简单神经网络框架

本框架基于计算图实现反向梯度传播 (Backpropagation, BP) 的简单神经网络。  

## 目前实现情况

1. **计算图节点定义**
    - 定义了计算节点（操作节点）和数据节点（变量节点），用于构建计算图。

2. **神经网络层定义**
    - 输入层
    - 隐藏层
    - 非线性函数层（如 ReLU、Sigmoid 等）
    - Softmax 层
    - 损失函数层（只实现了均方误差）

3. **层间连接**
    - 不同的层通过非线性函数层的两个函数（前向函数和反向函数）连接在一起。
    - 使得数据可以进行前向传播，梯度可以进行反向传播。

4. **反向传播实现**
    - 利用自动求导技术计算梯度。
    - **缺点**：由于采用自动求导，反向传播速度低于基于数学公式预推导的手动实现。

5. **训练方式**
    - 当前只能对样本逐个训练（随机梯度下降，SGD）。
    - 原因：尚未实现梯度累加以支持批量训练。

## 待改进方向

- 实现**梯度累加**，支持批量训练（Mini-batch Gradient Descent）。
- 优化计算图的反向传播效率，减少自动求导带来的开销。
- 权重的初始化，采用了固定的高斯分布。以后将改进为对应函数的高斯分布。
