# 基于计算图的简单神经网络框架

本框架是基于计算图实现反向梯度传播 (Backpropagation, BP) 的简单神经网络。  

## 实现情况

1. **计算图节点定义**
    - Node.h 定义了计算节点（操作节点）和数据节点（变量节点），用于构建计算图。

2. **神经网络层定义**
    - Layer.h
    - InputLayer(输入层)
    - HiddenLayer(隐藏层)
    - NonlinearLayer(非线性函数层(如 ReLU、Sigmoid 等))
    - SoftmaxLayer(Softmax 层)
    - MeanSquareErrorLayer CrossEntropyLossLayer(损失函数层)
    - ConvolutionLayer(卷积层）

3. **层间连接(main1.C main2.C)**
    - 不同的层通过非线性函数层或卷积层连接在一起。
    - 使得数据可以进行前向传播，梯度可以进行反向传播。

4. **反向传播实现**
    - 利用自动求导技术计算梯度。
    - **缺点**：由于采用自动求导，反向传播速度低于基于数学公式预推导的手动实现。

5. **训练方式**
    - 当前只能对样本逐个训练（随机梯度下降，SGD）。
    - 原因：尚未实现梯度累加以支持批量训练。

## 效果
- 目前在一些简单的二分类任务中，准确率可达90%以上，比如颜色的冷暖区分

## 待改进方向

- 实现**梯度累加**，支持批量训练（Mini-batch Gradient Descent）。
- 优化计算图的反向传播效率，减少自动求导带来的开销。
- 权重的初始化，采用了固定的高斯分布。以后将改进为对应函数的高斯分布。
- 卷积层只实现了单通道无填充卷积
